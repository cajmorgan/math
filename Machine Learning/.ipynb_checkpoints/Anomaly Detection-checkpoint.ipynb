{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4cdaca",
   "metadata": {},
   "source": [
    "# Anomaly Detection\n",
    "\n",
    "## Who's that weird guy?\n",
    "\n",
    "\n",
    "Anomaly Detection can both be supervised and unsupervised Machine Learning algorithms, but to be clear, it's generelly unsupervised. A short definition of an Anomaly is, quoted: \"*An outlier is an **observation** in a dataset which appears to be **inconsistent** with the remainder of that dataset*\" - Johnsson 1992 \n",
    "\n",
    "### Application Areas\n",
    "A very general example of Anomaly Detection that some people might have experienced are \"Transaction Blocks\", or basically when your bank system automatically decides to block a certain ingoing/outgoing payment. A summarized explaination of that is basically that this transaction differed somehow from **your** general transactions or/and general transactions from similar accounts other than yours specifically. \n",
    "\n",
    "Some general examples of applications for Anomaly Detection are the following:\n",
    "- Network Attack/Malware Detection (f.e DDoS attacks) \n",
    "- Insurance Fraud Detection\n",
    "- Damage Detections in real life components (f.e through sensors collecting data)\n",
    "- In Video/Images Surveillance, in many different situations\n",
    "\n",
    "In general, any application that is looking for data that doesn't fit with other data, **Anomalies**.\n",
    "\n",
    "### Supervised AD\n",
    "If it makes sense, AD can be used in a supervised fashion, where you label the anomalies in two classes, *normal* or *not-normal*. The problem with this method is that by the definition of an anomaly, it can occur basically anywhere it doesn't fit with the normal data. This can lead to that the classifier, f.e a logistic regression, separates the data-points in a way that won't be accurate on new anomalies, only for the current ones. The second problem is \"imbalanced classification\" which basically means that, usually anomalies are **rare** and you will generally not have enough data of anomalies for a good classified balance. So why would you use supervised AD? If you have a great well labeled dataset with a lot of anomalies examples and it makes sense for the current model, it could be a reasonable choice.\n",
    "\n",
    "### Novelty Detection\n",
    "This can be used when you only have data that is consider \"normal\" and don't contain any anomalies. It can be effective because when new data comes that don't conform to the previous used one, it will stick out like a sore thumb. One downside of this method is that, you need to be sure that the data doesn't contain any anomalies, because if you accidently classify anomalies as *normal*, your model will bias towards classifying new anomalies as normal.##\n",
    "\n",
    "### Unsupervised AD\n",
    "Probably the most common method in AD, where all the data is unlabeled and hence completely unsupervised. The data need to contain both anomalies and normal data and the general consideration is that the anomalies should be **rare**.\n",
    "\n",
    "### Output\n",
    "In a supervised setting, the output is two labels, normal or not-normal (or whatever you choose to call them).\n",
    "Otherwise it will be a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08ebd44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
