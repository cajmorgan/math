{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628377cb",
   "metadata": {},
   "source": [
    "# Matrices\n",
    "## Enter the matrix\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "a_{11} &  a_{12}  & \\ldots & a_{1n}\\\\\n",
    "a_{21}  &  a_{22} & \\ldots & a_{2n}\\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
    "a_{n1}  &   a_{n2}       &\\ldots & a_{nn}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### Basics\n",
    "\n",
    "Matrices are a set of very handy notations in Mathematics and are a core concept in Linear Algebra. Matrices can be viewed in many different ways, just a spreadsheet of numbers, columns of vectors, or the transformations, where every column represent where every unit vector will end up after applying the transformation to a vector (dot product). For example, in 2x2 matrix, the 2 columns can be viewed as the coordinates where the unit vectors $\\hat{i}$ (X-axis) and unit vector $\\hat{j}$ (Y-axis) ends up (from (1, 0) & (0, 1). \n",
    "\n",
    "**Note that to be able to apply a matrix to another entity, the number of rows of the matrix needs to equal the number of columns of the target**\n",
    "\n",
    "### Linear Transformations\n",
    "Lets define a matrix and the unit vectors in 2 dimensions:\n",
    "\n",
    "$A =\\begin{bmatrix}\n",
    "    2 & 4 \\\\\n",
    "    3 & 7 \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\hat{i} =\\begin{bmatrix}\n",
    "    1\\\\\n",
    "    0\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\hat{j} =\\begin{bmatrix}\n",
    "    0\\\\\n",
    "    1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "We want to apply the matrix transformation to the vector \n",
    "\n",
    "$v =\\begin{bmatrix}\n",
    "    5\\\\\n",
    "    4\n",
    "\\end{bmatrix}$\n",
    "\n",
    "which can be viewed as \n",
    "\n",
    "$v =\\begin{bmatrix}\n",
    "    5\\,\\hat{i}\\\\\n",
    "    4\\,\\hat{j}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "If the columns of A represents where the unit vectors will land after transformation,\n",
    "we can simply write down the following linear combination:\n",
    "\n",
    "$5\\begin{bmatrix}\n",
    "    2\\\\\n",
    "    3\n",
    "\\end{bmatrix} + 4\\begin{bmatrix}\n",
    "    4\\\\\n",
    "    7\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    26\\\\\n",
    "    43\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Which is the same as taking the dot product like:\n",
    "\n",
    "$A\\cdot v = \\begin{bmatrix}\n",
    "    2 & 4 \\\\\n",
    "    3 & 7 \\\\\n",
    "\\end{bmatrix} \\cdot \\begin{bmatrix}\n",
    "    5\\\\\n",
    "    4\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    26\\\\\n",
    "    43\n",
    "\\end{bmatrix}$\n",
    "\n",
    "### Matrix inversion $Ax = b, x = A^{-1}b $\n",
    "The inversion of a matrix is basically what matrix times the result $b$ of the first matrix transformation (linear combination) $Ax$ equals to $x$, i.e how to find the vector x if you have matrix A and the result b. \n",
    "\n",
    "Not all matrices are invertible, but when they are, finding the inversion of a matrix is usually done with Gaussian Elimination. \n",
    "\n",
    "#### Singular Matrices\n",
    "A singular matrix does **not** have an inverse. This happens when either the columns or the rows are multiples of each other or if combinations of them equals one of the other. Also, if you can find a vector that multiplies the matrix and produces $0$, it's singular. \n",
    "\n",
    "Geometrically if we look at the column picture described below, it means that the vectors points in the **same** direction and therefore they are the same vector by different scalars, hence singular, which even describes the word **singular** well.\n",
    "\n",
    "### Matrix Perspectives\n",
    "\n",
    "#### Row Picture\n",
    "The row picture is basically what we learn from the normal Algebra class, where we view every row of the matrix as the equation, f.e in 2 dimensions, x + y = 3 and draw the line that corresponds to that and the next row. The solution will be were those objects meet.\n",
    "\n",
    "#### Column Picture\n",
    "The column picture on the other hand is when we view the matrix as the vectors every column represents and draw the solution as a **linear combination**.\n",
    "\n",
    "\n",
    "\n",
    "#### Matrix Multiplication\n",
    "If you multiply matrix $A$ with matrix $B$, the columns of $A$ needs to be the same amount as the rows of $B$. If we on the other hand multiply $B$ with $A$ the inverse is true, therefore, applying matrices in different orders matter.\n",
    "\n",
    "Multiplying $A$ and $B$ gives two perspecitves of pictures, $A$ times every column of $B$ or every row of $A$ times matrix $B$.\n",
    "\n",
    "Another way of multiplying two matrices is basically by multiplying **columns of $A$** with **rows of $B$** and then add the resulting matrices.\n",
    "\n",
    "#### Resulting Vector\n",
    "A matrix with m rows and n columns $m\\times n$ times a matrix with n rows times p columns $n \\times p$ will produce a matrix with m rows and p columns $m \\times p$. This is pretty self-explanatory when understanding that multiplying a matrix with another matrix is basically multiplying a matrix times p vectors (with n rows). A matrix times a vector produces a vector, it transforms the vector. \n",
    "\n",
    "#### Entries\n",
    "A specific entry in a matrix $e_{ij}$ after multiplication can be found by looking at how the multiplication acts. If we want to find $C_{11}$ after multiplying matrices $A$ and $B$, we simply take the dot product of row 1 in matrix $A$ and column 1 in matrix $B$\n",
    "\n",
    "\n",
    "#### In Action\n",
    "*Note that multiplying from left creates row vectors and multiplying from right creates column vectors*\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "    a & b\\\\\n",
    "    c & d\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    e & f\\\\\n",
    "    g & h\n",
    "\\end{bmatrix}$\n",
    "\n",
    "When multiplying from left to right, you will multiply the rows of the right matrix by every instance of the left matrix and add the row vectors together. \n",
    "\n",
    "$a\\begin{bmatrix} e & f \\end{bmatrix} + b \\begin{bmatrix} g & h \\end{bmatrix} = \\begin{bmatrix} ae + bg & af + bh \\end{bmatrix}$\n",
    "\n",
    "$c \\begin{bmatrix}e & f \\end{bmatrix} + d \\begin{bmatrix} g & h \\end{bmatrix} = \\begin{bmatrix} ce + dg & cf + dh \\end{bmatrix}$\n",
    "\n",
    "$\\begin{bmatrix} ae + bg & af + bh\\\\\n",
    " ce + dg & cf + dh \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "When multiplying from right to left, the inverse is true, you will multiply the columns of the left matrix with the instances of the right. In my opinion, this one is easier too see. One row iteration to end per column on the right matrix creates one vector, then just put the created vectors in the same order!\n",
    "\n",
    "$e \\begin{bmatrix} a \\\\ c \\end{bmatrix} + g \\begin{bmatrix} b \\\\ d \\end{bmatrix}, \n",
    "f \\begin{bmatrix} a \\\\ c \\end{bmatrix} + h \\begin{bmatrix} b \\\\ d \\end{bmatrix} \n",
    "$\n",
    "\n",
    "$\\begin{bmatrix} ae + bg & af + bh\\\\\n",
    " ce + dg & cf + dh \\end{bmatrix}\n",
    "$\n",
    "\n",
    "As you can clearly see now, if we for some reason changed the order of the matrices, we still need to follow the same rules and hence the produced matrix will be different.\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "    e & f\\\\\n",
    "    g & h\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "    a & b\\\\\n",
    "    c & d\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$a \\begin{bmatrix} e \\\\ g \\end{bmatrix} + c \\begin{bmatrix} f \\\\ h \\end{bmatrix}, \n",
    "b \\begin{bmatrix} e \\\\ g \\end{bmatrix} + d \\begin{bmatrix} f \\\\ h \\end{bmatrix} \n",
    "$\n",
    "\n",
    "$\\begin{bmatrix} ae + cf & be + df \\\\\n",
    " ag + ch & bg + dh \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Elimination Matrix\n",
    "An elimination matrix is basically a matrix that can perform the steps of Gaussian Elimination just by multiplying. The notation could be f.e $E_{21}$ which would signify, the matrix that eleminates row 2 column 1 from the target, by definition turns it into 0.\n",
    "\n",
    "Let's use an example, we have the matrix $A = \\begin{bmatrix}\n",
    "    2 & 1 & 1\\\\\n",
    "    2 & 2 & 0\\\\\n",
    "    0 & 1 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "We can build the full elimination matrix $E$ by doing the steps in order $E_{nm}$.\n",
    "First we need to execute row 2 column 1 with $E_{21}$, then $E_{32}$ to get all the pivots.  \n",
    "\n",
    "$U = EA = E_{32}(E_{21}A) = (E_{32}E_{21})A$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b039c147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([[1,3],[2,7]])\n",
    "B = np.array([[7,-3],[-2,1]])\n",
    "\n",
    "A @ B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b4a28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f12e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
